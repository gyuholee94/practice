{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트&설치\n",
    "# !pip install dbfread\n",
    "# !pip install haversine\n",
    "# !pip install sklearn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from haversine import haversine\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline\n",
    "import platform\n",
    "import pickle\n",
    "import re\n",
    "platform.system()\n",
    "if platform.system() == 'Darwin': # Mac 환경 폰트 설정\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows': # Windows 환경 폰트 설정\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "plt.rc('axes', unicode_minus=False) # 마이너스 폰트 설정\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['종로구', '중구', '용산구', '성동구', '광진구', '동대문구', '중랑구', '성북구', '강북구']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gu_list = ['종로구','중구','용산구','성동구','광진구','동대문구','중랑구','성북구','강북구']\n",
    "gu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-c9e3a5aee931>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-c9e3a5aee931>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    query=양천구+%2B초등+%2B돌봄+&oquery=양천구\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "query=양천구+%2B초등+%2B돌봄+&oquery=양천구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 첫페이지, 기사제목 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "for keyword in gu_list:\n",
    "\n",
    "#     keyword\n",
    "    url = f'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={keyword}%2B초등+%2B돌봄+&oquery={keyword}'      \n",
    "\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    news_titles = soup.select('.news .type01 li dt a[title]')\n",
    "\n",
    "#     print('총', len(news_titles), '개의 뉴스 제목이 있습니다')\n",
    "    print()\n",
    "    for title in news_titles:\n",
    "        print(title['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 셀레니움댓글"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".u_cbox_btn_more\"}\n",
      "  (Session info: chrome=86.0.4240.75)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common import exceptions\n",
    "\n",
    "wd = \"./chromedriver.exe\"  # 다운 받은 웹드라이버 위치\n",
    "addr = \"https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=101&oid=008&aid=0004484978\" \n",
    "# 크롤링하고자하는 사이트 주소\n",
    "\n",
    "driver = webdriver.Chrome(wd)\n",
    "driver.get(addr)\n",
    "\n",
    "pages = 0 # 한 페이지당 약 20개의 댓글이 표시\n",
    "try:\n",
    "    while True: # 댓글 페이지가 몇개인지 모르므로.\n",
    "        driver.find_element_by_css_selector(\".u_cbox_btn_more\").click()\n",
    "        time.sleep(1.5)\n",
    "        print(pages, end=\" \")\n",
    "        pages+=1\n",
    "    \n",
    "except exceptions.ElementNotVisibleException as e: # 페이지 끝\n",
    "    pass\n",
    "    \n",
    "except Exception as e: # 다른 예외 발생시 확인\n",
    "    print(e)\n",
    "\n",
    "    \n",
    "html = driver.page_source\n",
    "dom = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "# 댓글이 들어있는 페이지 전체 크롤링\n",
    "comments_raw = dom.find_all(\"span\", {\"class\" : \"u_cbox_contents\"})\n",
    "\n",
    "# 댓글의 text만 뽑는다.\n",
    "comments = [comment.text for comment in comments_raw]\n",
    "\n",
    "comments[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제목, 날짜, 신문사, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "\n",
    "for keyword in gu_list:\n",
    "\n",
    "#     keyword\n",
    "#     url = f'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={keyword}%2B초등+%2B돌봄+&oquery={keyword}'      \n",
    "\n",
    "    csv_filename = \"naver_news_{}.csv\".format(keyword)\n",
    "    csv_open = open(csv_filename, \"w+\", encoding='utf-8')\n",
    "    csv_writer = csv.writer(csv_open)\n",
    "    csv_writer.writerow( ('제목', '날짜', '신문사', '링크', ) )  #제목 입력\n",
    "\n",
    "    # 총 100까지, 10페이지간의 간격으로 진행\n",
    "    for n in range(1,100,10):\n",
    "        req = requests.get(\"https://search.naver.com/search.naver?&where=news&query={}%2B초등+%2B돌봄+&oquery={}&start=\".format(keyword,keyword)+str(n), \n",
    "                            headers={'User-Agent':'Mozilla/5.0'})\n",
    "        html = req.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        articles = soup.select('ul.type01 > li')\n",
    "\n",
    "        for article in articles:\n",
    "            title = article.select_one(\"a._sp_each_title\").text          \n",
    "            # 기사 제목\n",
    "            others = article.select_one(\"dd.txt_inline\").text          \n",
    "            # date 추출을 위해 여러 정보를 불러옴\n",
    "            agency = article.select_one(\"span._sp_each_source\").text     \n",
    "            # 언론사\n",
    "            link = article.select_one(\"a._sp_each_title\")['href']\n",
    "\n",
    "            agency = agency.rstrip(\"언론사 선정\")                           \n",
    "            # 불필요한 문자 삭제\n",
    "\n",
    "            start = others.find('2')\n",
    "            end = start + 10\n",
    "            article_date = others[start:end]\n",
    "\n",
    "            csv_writer.writerow ( (title, article_date, agency, link, ) )\n",
    "\n",
    "    csv_open.close()\n",
    "\n",
    "#     pd.read_csv('{}'.format(keyword), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '종로구'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8044ac808865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgu_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1979\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1980\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1981\u001b[1;33m                 \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1982\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '종로구'"
     ]
    }
   ],
   "source": [
    "for keyword in gu_list:\n",
    "    pd.read_csv('{}'.format(keyword), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['종로구', '중구', '용산구', '성동구', '광진구', '동대문구', '중랑구', '성북구', '강북구']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>날짜</th>\n",
       "      <th>신문사</th>\n",
       "      <th>링크</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>성북·강북구 돌봄기관 인터넷에서 찾는다</td>\n",
       "      <td>2020.02.17</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>http://www.newsis.com/view/?id=NISX20200214_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서울 성북·강북구, 부산 사하구 등 11곳, 미래교육지구로 선정</td>\n",
       "      <td>2019.12.12</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>http://www.newsis.com/view/?id=NISX20191211_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[티브로드]&lt;서울&gt;강북구 내 돌봄 기관 웹서비스 시작</td>\n",
       "      <td>2020.02.18</td>\n",
       "      <td>SK브로드밴드</td>\n",
       "      <td>http://ch1.tbroad.com/content/view?parent_no=2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>집 찾아가 초등학생 원격수업 지원…강북구 돌봄서비스</td>\n",
       "      <td>2020.05.13</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>https://www.news1.kr/articles/?3933369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>강북구, 올해 지역일자리 5159개 창출 목표</td>\n",
       "      <td>2016.04.20</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>http://news1.kr/articles/?2640235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[금일 정치권 주요기사]“조수진 재산신고 역공”…“역대급 지원” 추경 7.8...</td>\n",
       "      <td>2020.09.10</td>\n",
       "      <td>청년일보</td>\n",
       "      <td>http://www.youthdaily.co.kr/news/article.html?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>서울 도심 자투리공간…공립 유치원 들어선다</td>\n",
       "      <td>28면1단  201</td>\n",
       "      <td>매일경제</td>\n",
       "      <td>http://news.mk.co.kr/newsRead.php?year=2019&amp;no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>사상 초유 4월 개학? 코로나19에 곳곳서 “개학 연기” 요구</td>\n",
       "      <td>2020.03.16</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>http://www.segye.com/content/html/2020/03/16/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>저마다 왕이 된 시대, 마을공동체가 갖는 의미</td>\n",
       "      <td>2018.12.17</td>\n",
       "      <td>오마이뉴스</td>\n",
       "      <td>http://www.ohmynews.com/NWS_Web/View/at_pg.asp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>혼밥보다 ‘마을부엌’…돈 아끼고 소외 이웃 챙기고 ‘1석2조’</td>\n",
       "      <td>2020.01.26</td>\n",
       "      <td>한겨레</td>\n",
       "      <td>http://www.hani.co.kr/arti/area/capital/925721...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               제목          날짜      신문사  \\\n",
       "0                           성북·강북구 돌봄기관 인터넷에서 찾는다  2020.02.17      뉴시스   \n",
       "1             서울 성북·강북구, 부산 사하구 등 11곳, 미래교육지구로 선정  2019.12.12      뉴시스   \n",
       "2                   [티브로드]<서울>강북구 내 돌봄 기관 웹서비스 시작  2020.02.18  SK브로드밴드   \n",
       "3                    집 찾아가 초등학생 원격수업 지원…강북구 돌봄서비스  2020.05.13      뉴스1   \n",
       "4                       강북구, 올해 지역일자리 5159개 창출 목표  2016.04.20      뉴스1   \n",
       "..                                            ...         ...      ...   \n",
       "95  [금일 정치권 주요기사]“조수진 재산신고 역공”…“역대급 지원” 추경 7.8...  2020.09.10     청년일보   \n",
       "96                        서울 도심 자투리공간…공립 유치원 들어선다  28면1단  201     매일경제   \n",
       "97             사상 초유 4월 개학? 코로나19에 곳곳서 “개학 연기” 요구  2020.03.16     세계일보   \n",
       "98                      저마다 왕이 된 시대, 마을공동체가 갖는 의미  2018.12.17    오마이뉴스   \n",
       "99             혼밥보다 ‘마을부엌’…돈 아끼고 소외 이웃 챙기고 ‘1석2조’  2020.01.26      한겨레   \n",
       "\n",
       "                                                   링크  \n",
       "0   http://www.newsis.com/view/?id=NISX20200214_00...  \n",
       "1   http://www.newsis.com/view/?id=NISX20191211_00...  \n",
       "2   http://ch1.tbroad.com/content/view?parent_no=2...  \n",
       "3              https://www.news1.kr/articles/?3933369  \n",
       "4                   http://news1.kr/articles/?2640235  \n",
       "..                                                ...  \n",
       "95  http://www.youthdaily.co.kr/news/article.html?...  \n",
       "96  http://news.mk.co.kr/newsRead.php?year=2019&no...  \n",
       "97  http://www.segye.com/content/html/2020/03/16/2...  \n",
       "98  http://www.ohmynews.com/NWS_Web/View/at_pg.asp...  \n",
       "99  http://www.hani.co.kr/arti/area/capital/925721...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('naver_news_강북구.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
